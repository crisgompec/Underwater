{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import dippykit as dip\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "#PICKING AN IMAGE\n",
    "im_original = cv2.imread(\"images/underwater-15.png\")\n",
    "cv2.imshow(\"Original image\", im_original)\n",
    "\n",
    "#Select pixels that are similar in color to skin\n",
    "im_skin = np.copy(im_original)\n",
    "for i in range(np.shape(im_original)[0]):\n",
    "    for j in range(np.shape(im_original)[1]):\n",
    "        if im_original[i,j][2] < 60:\n",
    "            im_skin[i,j]=[0,0,0]\n",
    "\n",
    "cv2.imshow(\"Zones similar to skin color\", im_skin)\n",
    "\n",
    "#Select zones with high luminosity (probably zones iluminated by refracted light)\n",
    "im_gray = cv2.cvtColor(im_original, cv2.COLOR_BGR2GRAY)\n",
    "ret,th1 = cv2.threshold(im_gray,180,255,cv2.THRESH_BINARY)\n",
    "cv2.imshow(\"Image after Binary Threshold\", th1)\n",
    "\n",
    "#Saliency detection\n",
    "# initialize OpenCV's static fine grained saliency detector and compute the saliency map\n",
    "saliency = cv2.saliency.StaticSaliencyFineGrained_create()\n",
    "(success, saliencyMap) = saliency.computeSaliency(im_original)\n",
    "cv2.imshow(\"Output of Saliency Detection\", saliencyMap)\n",
    "\n",
    "\n",
    "# if we would like a *binary* map that we could process for contours,\n",
    "# compute convex hull's, extract bounding boxes, etc., we can\n",
    "# additionally threshold the saliency map\n",
    "\n",
    "threshMap = cv2.threshold(saliencyMap*255, 80, 255,\n",
    "cv2.THRESH_BINARY)[1]\n",
    "cv2.imshow(\"Thresh\", threshMap)\n",
    "\n",
    "\n",
    "# record the results\n",
    "cv2.imwrite(\"temp_images/saliency.png\", saliencyMap*255)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "()\n",
      "True\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\n# loop over the detections\\nfor i in range(0, min(numDetections, args[\"max_detections\"])):\\n    # extract the bounding box coordinates\\n    (startX, startY, endX, endY) = saliencyMap[i].flatten()\\n\\n    # randomly generate a color for the object and draw it on the image\\n    output = image.copy()\\n    color = np.random.randint(0, 255, size=(3,))\\n    color = [int(c) for c in color]\\n    cv2.rectangle(output, (startX, startY), (endX, endY), color, 2)\\n \\n    # show the output image\\n    cv2.imshow(\"Image\", output)\\n    cv2.waitKey(0)\\n    \\n'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#PICKING AN IMAGE\n",
    "im_original = cv2.imread(\"images/underwater-15.png\")\n",
    "\n",
    "# initialize OpenCV's objectness saliency detector and set the path\n",
    "# to the input model files\n",
    "saliency = cv2.saliency.ObjectnessBING_create()\n",
    "saliency.setTrainingPath('ObjectnessTrainedModel')\n",
    " \n",
    "# compute the bounding box predictions used to indicate saliency\n",
    "(success, saliencyMap) = saliency.computeSaliency(im_original)\n",
    "\n",
    "print(np.shape(saliencyMap))\n",
    "print(success)\n",
    "\"\"\"\n",
    "# loop over the detections\n",
    "for i in range(0, min(numDetections, args[\"max_detections\"])):\n",
    "    # extract the bounding box coordinates\n",
    "    (startX, startY, endX, endY) = saliencyMap[i].flatten()\n",
    "\n",
    "    # randomly generate a color for the object and draw it on the image\n",
    "    output = image.copy()\n",
    "    color = np.random.randint(0, 255, size=(3,))\n",
    "    color = [int(c) for c in color]\n",
    "    cv2.rectangle(output, (startX, startY), (endX, endY), color, 2)\n",
    " \n",
    "    # show the output image\n",
    "    cv2.imshow(\"Image\", output)\n",
    "    cv2.waitKey(0)\n",
    "    \n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
